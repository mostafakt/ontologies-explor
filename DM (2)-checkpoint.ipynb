{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCSnQZ6IxzsQ",
    "outputId": "f6ad1e90-37c7-4d18-b8d4-9527b469d3c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# !pip install beautifulsoup4\n",
    "# !pip install owlready2\n",
    "# !pip install fuzzywuzzy\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UGToULB72dEV",
    "outputId": "9158e0d0-7cee-4b88-f191-3b062b2bf109"
   },
   "outputs": [],
   "source": [
    "from owlready2 import * \n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Tki6tjtk96kL"
   },
   "outputs": [],
   "source": [
    "# onto1 = get_ontology(\"/content/drive/MyDrive/OWl/ontologies/ML.owl\").load()\n",
    "\n",
    "# onto2 = get_ontology(\"/content/drive/MyDrive/OWl/ontologies/Regression.owl\").load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "524w71eHrfA6",
    "outputId": "743fdedd-6c66-47f9-d666-7f62243a4918"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # list(onto1.classes())[0].is_a.append(list(onto2.classes())[3])\n",
    "# # print(list(onto1.classes())[0].is_a)\n",
    "\n",
    "# print(list(onto1.classes())[0].instances()[0].equivalent_to)\n",
    "# list(onto1.classes())[0].instances()[0].equivalent_to.append(list(onto2.classes())[3].instances()[0])\n",
    "# print(list(onto1.classes())[0].instances()[0].equivalent_to)\n",
    "\n",
    "# print(list(onto1.classes()))\n",
    "# print(list(onto2.classes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Fv7BhZNTCGI5"
   },
   "outputs": [],
   "source": [
    "def nameSimMeasur(name1,name2):\n",
    "    lens=fuzz.partial_ratio(name1,name2)\n",
    "    s=\"names: \"+name1 +\" \"+name2 +\"  \"+  str(lens)\n",
    "\n",
    "    return lens,s\n",
    "def parentSimMeasur(parent1,parent2):\n",
    "    parent1=parent1.name\n",
    "    parent2=parent2.name\n",
    "    lens=fuzz.partial_ratio(parent1,parent2)\n",
    "    s=\"parent names: \"+parent1 +\" \"+parent2 +\"  \"+  str(lens)\n",
    "    return lens,s\n",
    "def pathSimMeasur(path1,path2):\n",
    "    path1=path1.split(\"/\")[len(path1.split(\"/\"))-1]\n",
    "    path2=path2.split(\"/\")[len(path2.split(\"/\"))-1]\n",
    "    lens=fuzz.ratio(path1,path2)\n",
    "    s=\"paths: \"+path1 +\" \"+path2 +\"  \"+  str(len)\n",
    "    return lens,s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7sWbyyKZSFLT",
    "outputId": "f3047d0c-1ba9-467b-b4ec-2601856cc5e4"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'typing_extensions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15880/3002623231.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalculateClassSimMeasure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mentity2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mname1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mentity1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'typing_extensions'"
     ]
    }
   ],
   "source": [
    "from typing_extensions import Concatenate\n",
    "\n",
    "\n",
    "def calculateClassSimMeasure(entity1,entity2):\n",
    "    name1=entity1.name\n",
    "    name2=entity2.name\n",
    "    nameMeasur,s=nameSimMeasur(name1,name2)\n",
    "    return nameMeasur, s\n",
    "\n",
    "def calculateInstancesAllSimMeasures(entity1,entity2):\n",
    "    name1=entity1.name\n",
    "    name2=entity2.name\n",
    "    path1=entity1.iri\n",
    "    path2=entity2.iri\n",
    "    nameMeasur,s=nameSimMeasur(name1,name2)\n",
    "    pathMeasur,ss=pathSimMeasur(path1,path2)\n",
    "\n",
    "    return [nameMeasur,pathMeasur],(s+\"\\n\"+ss)\n",
    "\n",
    "class1=list(onto1.classes())\n",
    "class2=list(onto2.classes())\n",
    "props1=list(onto1.properties())\n",
    "props2=list(onto2.properties())\n",
    "print( calculateAllSimMeasures( class1[0],class2[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "536Snq_efPtW",
    "outputId": "0ecdaf94-5c7e-47a1-c037-4dcc1acffd4b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15880/1054573615.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# class1[2].instances()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0monto1\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mAlgorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mThing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'class1' is not defined"
     ]
    }
   ],
   "source": [
    "print(class1,class2)\n",
    "# class1[2].instances()\n",
    "with onto1 :\n",
    "    class Algorithm(Thing):\n",
    "        pass\n",
    "\n",
    "# str(Function.instances()[0].is_a).split(\".\")[1][:-1]\n",
    "print(Algorithm.instances())\n",
    "for i in Algorithm.instances():\n",
    "\n",
    "    print(i.is_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOfyAtksXq9m"
   },
   "outputs": [],
   "source": [
    "# def createInstancesAlignment(classes1,classes2,threshold=[60,60]):\n",
    "#     # match between instance of class\n",
    "#     entities1=classes1.instances()\n",
    "#     entities2=classes2.instances()\n",
    "#     matches=[]\n",
    "#     for en1 in entities1:\n",
    "#         for en2 in entities2:\n",
    "#             simMeasur,s=calculateInstancesAllSimMeasures(en1,en2) \n",
    "\n",
    "#             match=True\n",
    "#             for sim in simMeasur:\n",
    "#                 if (sim <threshold[i]):\n",
    "#                     match=False\n",
    "#                     break \n",
    "#             if (match):\n",
    "#                 print(s)\n",
    "#                 matches.append(match)\n",
    "#     return matches\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "vYQFDTd-5NsC",
    "outputId": "805fc81a-3c88-4ca0-e5a5-c61bafc73b61"
   },
   "outputs": [],
   "source": [
    "onto2.base_iri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "jnl1VnDa55ax",
    "outputId": "f57d564c-296c-4f7d-ae18-d87bfb72f533"
   },
   "outputs": [],
   "source": [
    "list(onto2.classes())\n",
    "list(onto2.classes())[0].iri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fagnamDV7Nma"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZN2SoNEa5vVp"
   },
   "outputs": [],
   "source": [
    "\n",
    "ontos = get_ontology(\"https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf#\").load()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_z1F5_U6Cjc",
    "outputId": "6a41d6f8-4312-4f7f-8bff-ba09393179b3"
   },
   "outputs": [],
   "source": [
    "list(ontos.classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOWlmg_5B3wV"
   },
   "outputs": [],
   "source": [
    " \n",
    "def createAlignment(ont1,ont2, threshold):\n",
    "    #class matches /Props\n",
    "    classes1=list(ont1.classes())\n",
    "    classes2=list(ont2.classes()) \n",
    "    # ontoRes=get_ontology(\"/content/drive/MyDrive/OWl/ontologies/tes6.owl\")\n",
    "    # nameSpace=ontoRes.get_namespace(entities1.base_iri)\n",
    "    # with ontoRes:\n",
    "    #     namespace=nameSpace\n",
    "        \n",
    "    # ontoRes=ontoRes.get_namespace(entities1.base_iri)\n",
    "\n",
    "    ithr = threshold[1:]\n",
    "\n",
    "    for class1 in classes1:\n",
    "        for class2 in classes2:\n",
    "            # ontoRes.new_class(\"NewClassName\", (Thing))\n",
    "\n",
    "            sim, _ = calculateClassSimMeasure(class1, class2)\n",
    "            if sim >= threshold[0]:\n",
    "                class1.is_a.append(class2)\n",
    "                print(\"Class equvilant:\", class1, class2)\n",
    "\n",
    "                # instances allignement\n",
    "                entities1=class1.instances()\n",
    "                entities2=class2.instances()\n",
    "                for en1 in entities1:\n",
    "                    for en2 in entities2:\n",
    "                        print(\"candidate:\", en1, en2)\n",
    "                        simMeasur, _ = calculateInstancesAllSimMeasures(en1, en2) \n",
    "\n",
    "                        match = True\n",
    "                        for thr, targetThe in zip(simMeasur, ithr):\n",
    "                          if thr < targetThe:\n",
    "                            match = False\n",
    "                            break\n",
    "                        if match:\n",
    "                          en2.INDIRECT_equivalent_to.append(en1)\n",
    "                          print(\"equavilant: \", en1, en2)\n",
    "                          # print()\n",
    "                          # new_en1 = new_class1.is_a[-1]\n",
    "                          # new_en2 = new_class2.is_a[-1]\n",
    "\n",
    "                          # new_en1.equivalent_to.append(new_en2)\n",
    "                          # new_en2.equivalent_to.append(new_en1)\n",
    "\n",
    "                # with ontoRes:\n",
    "                #   new_class1 = None\n",
    "                #   new_class2 = None\n",
    "                #   has1 = str(class1) in classes_names\n",
    "                #   has1 = str(class2) in classes_names\n",
    "\n",
    "                #   for classObj in ontoRes.classes():\n",
    "                #     if classObj.name == class1.name:\n",
    "                #       new_class1 = classObj\n",
    "                #       has1 = True\n",
    "                #     if classObj.name == class2.name:\n",
    "                #       new_class2 = classObj\n",
    "                #       has2 = True\n",
    "\n",
    "                     \n",
    "                #   if new_class1 == None:\n",
    "                #     new_class1 = types.new_class(class1.name, (class1,))\n",
    "                #   if new_class2 == None:\n",
    "                #     new_class2 = types.new_class(class2.name, (class2,)) \n",
    "\n",
    "\n",
    "                #   if not has1 or not has2:\n",
    "                #     new_class1.equivalent_to.append(new_class2)\n",
    "                #     new_class2.equivalent_to.append(new_class1)\n",
    "\n",
    "                #   # instances allignement\n",
    "                #   entities1=class1.instances()\n",
    "                #   entities2=class2.instances()\n",
    "                  \n",
    "\n",
    "                #   for en1 in entities1:\n",
    "                #       for en2 in entities2:\n",
    "                #           simMeasur, _=calculateInstancesAllSimMeasures(en1,en2) \n",
    "\n",
    "                #           match = True\n",
    "                #           for thr, targetThe in zip(simMeasur, ithr):\n",
    "                #             if thr < targetThe:\n",
    "                #               match = False\n",
    "                #               break\n",
    "                #           if match:\n",
    "\n",
    "                #             new_class1.instances().append(en1)\n",
    "                #             new_class2.instances().append(en2)\n",
    "\n",
    "                #             new_en1 = new_class1.is_a[-1]\n",
    "                #             new_en2 = new_class2.is_a[-1]\n",
    "\n",
    "                #             new_en1.equivalent_to.append(new_en2)\n",
    "                #             new_en2.equivalent_to.append(new_en1)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "                  # print(\"equavilant\", new_class1.name, new_class2.name)\n",
    "                \n",
    "\n",
    "                # print(list(ontoRes.classes())[1].equivalent_to)      \n",
    "                # print(list(ontoRes.classes()))\n",
    "                  \n",
    "                  \n",
    "                  \n",
    "                  # \"------print(s)\n",
    "                  # print(----------------\")\n",
    "            # matches.append(match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDaPHyIoVGRV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_qn97CRVGzk"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1y8SxKC4QHWn"
   },
   "source": [
    "#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "Fa1lIyA9PLs5",
    "outputId": "65c59410-ff0d-4a69-ae52-86c244e8af29"
   },
   "outputs": [],
   "source": [
    "def evalEntitiesMatch(class1,class2):\n",
    "    i=0\n",
    "    j=0\n",
    "    for c in createAlignment(class1,class2):\n",
    "        print ([c,j])\n",
    "        if (c):\n",
    "            i+=1\n",
    "        j+=1  \n",
    "\n",
    "    print (i)\n",
    "evalEntitiesMatch(class1,class2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cNC7PYoc4S-"
   },
   "outputs": [],
   "source": [
    "def printRes(onto):\n",
    "  cls = list(onto.classes())\n",
    "  print(len(cls))\n",
    "  print(cls)\n",
    "\n",
    "  for c in onto.classes():\n",
    "    print(\"Class:\", c.name)\n",
    "    print(list(c.equivalent_to))\n",
    "\n",
    "    for ins in c.instances():\n",
    "      print(\"Instance:\", ins.name)\n",
    "      print(ins.equivalent_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJj5pyUB9JLK"
   },
   "outputs": [],
   "source": [
    "def trainAllOwls():\n",
    "    links=[]\n",
    "    for root, dirs, files in os.walk(\"C:\\Users\\ACER\\Desktop\\New folder\\ontologies\", topdown=False):\n",
    "        for name in files:\n",
    "            links.append(os.path.join(root, name))\n",
    "\n",
    "    for i in range(len(links)):\n",
    "      for j in range(len(links)):\n",
    "        if j > i:\n",
    "          ont1 = get_ontology(links[i]).load()\n",
    "          ont2 = get_ontology(links[j]).load()\n",
    "          # class1=list(onto1.classes())\n",
    "          # class2=list(onto2.classes())\n",
    "          # creat alignment for all class \n",
    "          createAlignment(onto1, onto2, [90, 30, 30])\n",
    "          # creat alignment for all props \n",
    "          # createAlignment(props1,props2)\n",
    "    \n",
    "    return        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Kw484fg1AAq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rUReO99yG8nY",
    "outputId": "b5c27536-8e3e-409c-ebf1-b38438a15444"
   },
   "outputs": [],
   "source": [
    "trainAllOwls()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHnpWzAwfS4i",
    "outputId": "f11a3c26-3ab2-4951-dc82-556ad6962b31"
   },
   "outputs": [],
   "source": [
    "ontoRes=get_ontology(resOntoName).load()\n",
    "printRes(ontoRes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GK3ax2SoQNMw"
   },
   "source": [
    "#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtgAmhBz8sDR",
    "outputId": "a9efa941-74e9-433e-a288-2730670e8b59"
   },
   "outputs": [],
   "source": [
    "ontoRes=get_ontology(resOntoName).load()\n",
    "# printRes(ontoRes)\n",
    "classes = list(ontoRes.classes())\n",
    "\n",
    "for c in \n",
    "print(str(classes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Cb7Yh_G-z-5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
